{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NguyenPhamQuocHuy-20130283/20130283_NguyenPhamQuocHuy_ML2023/blob/main/Lab_7_20130283_NguyenPhamQuocHuy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab deals with **cross validation** for some classification algorithms and **clustering methods**. \n",
        "\n",
        "*   **Deadline: 23:59, 10/4/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "DoVWQ8AEyc-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a5c71c7-fe7a-4da3-810f-c5a333e0bf9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "# code\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import datasets\n",
        "from sklearn import svm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import CategoricalNB, BernoulliNB, ComplementNB, GaussianNB, MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest, chi2, RFE, SelectFromModel\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/Colab Notebooks'\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. With **iris** dataset\n",
        "*  1.1. Apply **SVM** algorithm with cross validation\n"
      ],
      "metadata": {
        "id": "x_dG9SA5OhGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "x = datasets.load_iris().data\n",
        "y = datasets.load_iris().target\n",
        "\n",
        "clf = svm.SVC(kernel=\"sigmoid\", random_state=0)\n",
        "scores = cross_validate(clf, x, y, scoring='accuracy', cv=10)\n",
        "\n",
        "print(sorted(scores.keys()))\n",
        "print(np.mean(scores['test_score']))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "62jExOZ952fF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74136383-ad4f-4c0b-fdd6-21f22d229c17"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fit_time', 'score_time', 'test_score']\n",
            "0.06666666666666668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  1.2 Apply **feature selection** to the dataset and then use **RandomForest** algorithm with cross validation "
      ],
      "metadata": {
        "id": "2g--8cng53sY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "x_new = SelectKBest(chi2, k='all').fit_transform(x, y)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_new, y, test_size=0.3)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf_scores = cross_validate(rf, x_train, y_train, scoring=\"accuracy\", cv=10);\n",
        "\n",
        "print(sorted(rf_scores.keys()))\n",
        "print(np.mean(rf_scores['test_score']))\n"
      ],
      "metadata": {
        "id": "fX0_kItYPism",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d275d01-4cea-4ea7-a166-e9f373103e12"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fit_time', 'score_time', 'test_score']\n",
            "0.9354545454545455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jabEEOv516EP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. With mnist dataset: \n",
        "*   2.1. Apply **K-Means** algorithm using k=10, "
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import mode\n",
        "# loading dataset\n",
        "dataset = datasets.load_iris()\n",
        "# building model\n",
        "x_train, x_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.3)\n",
        "kmeans = KMeans(n_clusters=10, random_state=42)\n",
        "kmeans.fit(x_train, y_train)\n",
        "\n",
        "kmean_y = kmeans.predict(x_train)\n",
        "\n",
        "\n",
        "\n",
        "print(accuracy_score(y_train, kmean_y))"
      ],
      "metadata": {
        "id": "sOsg77IBzEyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d1f3bde-bda0-414c-ffc5-bfb9547117fc"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10476190476190476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.2. Compare the obtained result with with other classification algorithms such as **Randomforest**, **kNN**, and **Na√Øve Bayes** in terms of accuracy, precision, recall, f1 using cross validation. \n"
      ],
      "metadata": {
        "id": "pnoVB8J4vV36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.lib.function_base import average\n",
        "# code\n",
        "dataset = datasets.load_iris()\n",
        "x_train, x_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.3)\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(x_train, y_train)\n",
        "rf_pred = rf.predict(x_test)\n",
        "\n",
        "# Naive bayes\n",
        "gauss = GaussianNB()\n",
        "gauss.fit(x_train, y_train)\n",
        "gauss_pred = gauss.predict(x_test)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=30)\n",
        "knn.fit(x_train, y_train)\n",
        "knn_pred = knn.predict(x_test);\n",
        "\n",
        "kmeans = KMeans(n_clusters=10, random_state=42)\n",
        "kmeans.fit(x_train, y_train)\n",
        "\n",
        "kmean_y = kmeans.predict(x_test)\n",
        "\n",
        "t = PrettyTable([\"Algorithm\",\"Accuracy\",\"Precision\", \"Recall\", \"F1\"])\n",
        "t.add_row([\"KNN\", round(accuracy_score(y_test, knn_pred), 2), \n",
        "           round(precision_score(y_test, knn_pred, average='micro'), 2), \n",
        "           round(recall_score(y_test, knn_pred, average='macro'), 2),\n",
        "           round(f1_score(y_test, knn_pred,average='macro'), 2)])\n",
        "t.add_row([\"Random forest\", round(accuracy_score(y_test, rf_pred), 2), \n",
        "           round(precision_score(y_test, rf_pred, average='micro'), 2), \n",
        "           round(recall_score(y_test, rf_pred, average='macro'), 2),\n",
        "           round(f1_score(y_test, rf_pred,average='macro'), 2)])\n",
        "t.add_row([\"Naive Bayes\", round(accuracy_score(y_test, gauss_pred), 2), \n",
        "           round(precision_score(y_test, gauss_pred, average='micro'), 2), \n",
        "           round(recall_score(y_test, gauss_pred, average='macro'), 2),\n",
        "           round(f1_score(y_test, gauss_pred,average='macro'), 2)])\n",
        "t.add_row([\"K Means\", round(accuracy_score(y_test, kmean_y), 2), \n",
        "           round(precision_score(y_test, kmean_y, average='micro'), 2), \n",
        "           round(recall_score(y_test, kmean_y, average='macro'), 2),\n",
        "           round(f1_score(y_test, kmean_y,average='macro'), 2)])\n",
        "print(t)"
      ],
      "metadata": {
        "id": "-ZTSvsJdvYqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a8b304f-373e-4fd0-d57c-774ceda63b5f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+----------+-----------+--------+------+\n",
            "|   Algorithm   | Accuracy | Precision | Recall |  F1  |\n",
            "+---------------+----------+-----------+--------+------+\n",
            "|      KNN      |   0.91   |    0.91   |  0.92  | 0.92 |\n",
            "| Random forest |   0.96   |    0.96   |  0.96  | 0.96 |\n",
            "|  Naive Bayes  |   0.96   |    0.96   |  0.96  | 0.96 |\n",
            "|    K Means    |   0.02   |    0.02   |  0.01  | 0.01 |\n",
            "+---------------+----------+-----------+--------+------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.3. From the obtained results, **which approach is better** for this problem: Supervised learning or Unsupervised learning?"
      ],
      "metadata": {
        "id": "uyey-ndXvZlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "Qzh_D-rgvbv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.4. Apply **AgglomerativeClustering** algorithm to mnist dataset using the number of clusters is 10"
      ],
      "metadata": {
        "id": "ol1U_T_NvcqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3. \n",
        "For given dataset (shopping-data.csv) including 5 attributes: **CustomerID**, **Genre**, **Age**, **Annual Income**, and **Spending Score**.\n",
        "*   3.1. Using the **scipy library** to create the dendrograms for the given dataset (remember drop categorical attributes: **CustomerID**, **Genre**)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "YYY2dLtH3P8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.2. Apply K-Means to the preprocessed dataset with k belongs to [2,10]. Then compute SSE values and plot them to find the best value of k."
      ],
      "metadata": {
        "id": "eHlh_dWUyEMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "8vx3mfIidu4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.2. From the obtained dengrograms, choose an appropriate number of clusters and apply **AgglomerativeClustering** algorithm to the given dataset"
      ],
      "metadata": {
        "id": "RJpsTIiyv-1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "5ZE7A0Au1Pg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}